{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json \n",
    "import joblib\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "import yaml\n",
    "\n",
    "# TO CHANGE\n",
    "BASEDIR = \"../../../\"\n",
    "sys.path.insert(0, BASEDIR)\n",
    "\n",
    "from src.pipelines.memorize import MemPipelineConfig, MemPipeline, LLMExtractorConfig, LLMUpdatorConfig\n",
    "from src.kg_model import KnowledgeGraphModel, EmbeddingsModelConfig, GraphModelConfig, EmbedderModelConfig\n",
    "from src.db_drivers.graph_driver import GraphDBConnectionConfig, GraphDriverConfig\n",
    "from src.db_drivers.vector_driver import VectorDBConnectionConfig, VectorDriverConfig\n",
    "\n",
    "# gigachat key\n",
    "#GIGACHAT_CREDS = 'OWUwOGUzOWEtMjJiNi00YmMxLThmMmItNzMwNjM2MTI2YmYxOjg2ODdiOTVhLTZkNDctNGFjOC1iMmViLTEyNDA5MmFiN2Q5Mw=='\n",
    "# openai key\n",
    "#API_KEY = \"'sk-861mINAavom2SSBqgrI82D4thMOfqT37knCof2o0H0T3BlbkFJ2gdVXJuVjNesNNP2aeUwPoBpZP3a3R1gn1kqv97CsA'\"\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting knowledge-graph configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read YAML file\n",
    "with open(\"params.yaml\", 'r') as stream:\n",
    "    HYPER_PARAMS = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"../../../data/knowledge_graphs/\"\n",
    "DATASET_PATH = BASE_PATH + f\"{HYPER_PARAMS['DATASET_NAME']}/\"\n",
    "KG_PATH = DATASET_PATH + f\"{HYPER_PARAMS['KNOWLEDGE_GRAPH_NAME']}/\"\n",
    "\n",
    "HYPER_PARAMS_PATH = KG_PATH + 'hyperparameters.json'\n",
    "EXTRACTED_TRIPLETS_PATH = KG_PATH + \"extracted_triplets\"\n",
    "GRAPH_DRIVER_CONFIG_PATH = KG_PATH + \"graph_config\"\n",
    "EMBEDDINGS_DRIVER_CONFIG_PATH = KG_PATH + \"embeddings_config\"\n",
    "MEM_PIPELINE_CONFIG_PATH = KG_PATH + \"mem_pipeline_config\"\n",
    "\n",
    "VECTORIZED_DB_PATH = KG_PATH + \"embeddings_part/\"\n",
    "GRAPH_DB_PATH = KG_PATH + \"graph_part/\"\n",
    "CACHE_DB_PATH = KG_PATH + \"cache_part/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(BASE_PATH):\n",
    "    raise ValueError(f\"Директории не существует: {BASE_PATH}\")\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    raise ValueError(f\"Директории не существует: {DATASET_PATH}\")\n",
    "if os.path.exists(KG_PATH):\n",
    "    raise ValueError(f\"Директория существует: {KG_PATH}\")\n",
    "\n",
    "os.mkdir(KG_PATH)\n",
    "os.mkdir(VECTORIZED_DB_PATH)\n",
    "os.mkdir(GRAPH_DB_PATH)\n",
    "os.mkdir(CACHE_DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../data/knowledge_graphs/diaasqa/gigachat_filtered/embeddings_part/\n",
      "../../../data/knowledge_graphs/diaasqa/gigachat_filtered/graph_part/\n",
      "../../../data/knowledge_graphs/diaasqa/gigachat_filtered/cache_part/\n"
     ]
    }
   ],
   "source": [
    "print(VECTORIZED_DB_PATH)\n",
    "print(GRAPH_DB_PATH)\n",
    "print(CACHE_DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting knowledge graph\n",
    "\n",
    "graph_config = GraphModelConfig(\n",
    "    driver_config=GraphDriverConfig(\n",
    "        db_vendor='neo4j',\n",
    "        db_config=GraphDBConnectionConfig(\n",
    "            uri=\"bolt://personalai_mmenschikov_neo4j:7687\", params={'user': \"neo4j\", 'pwd': 'password'},\n",
    "            need_to_clear=HYPER_PARAMS['need_to_clear'])))\n",
    "\n",
    "embed_config = EmbeddingsModelConfig(\n",
    "    nodesdb_driver_config=VectorDriverConfig(\n",
    "        db_vendor='chroma',\n",
    "        db_config=VectorDBConnectionConfig(\n",
    "            path=VECTORIZED_DB_PATH, db_info={'db': 'personalaidb', 'table': \"vectorized_nodes\"}, need_to_clear=HYPER_PARAMS['need_to_clear'])),\n",
    "    tripletsdb_driver_config=VectorDriverConfig(\n",
    "        db_vendor='chroma',\n",
    "        db_config=VectorDBConnectionConfig(\n",
    "            path=VECTORIZED_DB_PATH, db_info={'db': 'personalaidb', 'table': \"vectorized_triplets\"}, need_to_clear=HYPER_PARAMS['need_to_clear'])),\n",
    "    embedder_config=EmbedderModelConfig(model_name_or_path=HYPER_PARAMS['EMBEDDER_MODEL_PATH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_model = KnowledgeGraphModel(\n",
    "    graph_config=graph_config,\n",
    "    embeddings_config=embed_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "{'triplets': 182838, 'nodes': 49597}\n"
     ]
    }
   ],
   "source": [
    "print(kg_model.embeddings_struct.vectordbs['nodes'].count_items())\n",
    "print(kg_model.embeddings_struct.vectordbs['triplets'].count_items())\n",
    "print(kg_model.graph_struct.db_conn.count_items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Memorization Pipeline\n",
    "\n",
    "mem_config = MemPipelineConfig(\n",
    "    extractor_config=LLMExtractorConfig(),\n",
    "    updator_config=LLMUpdatorConfig(\n",
    "        delete_obsolete_info=HYPER_PARAMS['DELETE_OBSOLETE_INFO']))\n",
    "\n",
    "mem_pipeline = MemPipeline(kg_model, mem_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../data/knowledge_graphs/diaasqa/gigachat_full/mem_pipeline_config']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(HYPER_PARAMS_PATH, 'w', encoding='utf-8') as fd:\n",
    "    fd.write(json.dumps(HYPER_PARAMS, ensure_ascii=False, indent=1))\n",
    "\n",
    "joblib.dump(graph_config, GRAPH_DRIVER_CONFIG_PATH)\n",
    "joblib.dump(embed_config, EMBEDDINGS_DRIVER_CONFIG_PATH)\n",
    "joblib.dump(mem_config, MEM_PIPELINE_CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_diaasqa_load(dataset_path: str) -> List[Tuple[str, Dict[str, str]]]:\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as fd:\n",
    "        data = json.loads(fd.read())\n",
    "\n",
    "    data_pairs = []\n",
    "    for item in data['data']:\n",
    "        data_pairs.append((item['text_dialog'], {'time': item['time'].split(',')[0]}))\n",
    "\n",
    "    return data_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_LOAD_FUNCS = {\n",
    "    'diaasqa': custom_diaasqa_load\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CUSTOM_LOAD_FUNCS[HYPER_PARAMS['DATASET_NAME']](HYPER_PARAMS['DATASET_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3483\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_triplets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2106 | gigachat_full | diaasqa |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 102/1377 [31:00<7:17:29, 20.59s/it]AUTHENTICATION ERROR\n",
      " 15%|█▍        | 204/1377 [1:02:19<6:35:04, 20.21s/it]AUTHENTICATION ERROR\n",
      " 22%|██▏       | 307/1377 [1:33:30<5:31:51, 18.61s/it]AUTHENTICATION ERROR\n",
      " 29%|██▉       | 404/1377 [2:04:37<5:24:09, 19.99s/it]AUTHENTICATION ERROR\n",
      " 36%|███▌      | 494/1377 [2:35:59<5:08:53, 20.99s/it]AUTHENTICATION ERROR\n",
      " 43%|████▎     | 590/1377 [3:07:13<4:54:21, 22.44s/it]AUTHENTICATION ERROR\n",
      " 49%|████▉     | 674/1377 [3:38:19<4:38:00, 23.73s/it] AUTHENTICATION ERROR\n",
      " 55%|█████▌    | 758/1377 [4:09:40<3:53:33, 22.64s/it]AUTHENTICATION ERROR\n",
      " 61%|██████▏   | 846/1377 [4:40:57<2:59:33, 20.29s/it]AUTHENTICATION ERROR\n",
      " 68%|██████▊   | 934/1377 [5:12:04<2:27:03, 19.92s/it]AUTHENTICATION ERROR\n",
      " 74%|███████▍  | 1017/1377 [5:43:09<2:02:05, 20.35s/it]AUTHENTICATION ERROR\n",
      " 80%|████████  | 1103/1377 [6:14:19<1:43:56, 22.76s/it]AUTHENTICATION ERROR\n",
      " 86%|████████▋ | 1188/1377 [6:45:32<1:07:38, 21.48s/it]AUTHENTICATION ERROR\n",
      " 92%|█████████▏| 1265/1377 [7:16:49<44:04, 23.61s/it]  AUTHENTICATION ERROR\n",
      " 98%|█████████▊| 1343/1377 [7:47:51<11:54, 21.02s/it]  AUTHENTICATION ERROR\n",
      "100%|██████████| 1377/1377 [8:02:36<00:00, 21.03s/it]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(dataset[2106:]):\n",
    "    text, properties = item[0], item[1]\n",
    "    extracted_triplets, _ = mem_pipeline.remember(text, properties)\n",
    "    saved_triplets.append(extracted_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kg_model.embeddings_struct.vectordbs['nodes'].count_items())\n",
    "print(kg_model.embeddings_struct.vectordbs['triplets'].count_items())\n",
    "print(kg_model.graph_struct.db_conn.count_items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving log inforamtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/knowledge_graphs/diaasqa/gigachat_full/mem_pipeline_config']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(saved_triplets, EXTRACTED_TRIPLETS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build graph on extracted triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_triplets = joblib.load(EXTRACTED_TRIPLETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_triplets = reduce(lambda acc, v: acc + v, saved_triplets, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mem_pipeline.updator.kg_model.graph_struct.create_triplets(flattened_triplets, status_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mem_pipeline.updator.kg_model.embeddings_struct.create_triplets(flattened_triplets, status_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49597\n",
      "44328\n",
      "{'triplets': 182838, 'nodes': 49597}\n"
     ]
    }
   ],
   "source": [
    "print(kg_model.embeddings_struct.vectordbs['nodes'].count_items())\n",
    "print(kg_model.embeddings_struct.vectordbs['triplets'].count_items())\n",
    "print(kg_model.graph_struct.db_conn.count_items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
