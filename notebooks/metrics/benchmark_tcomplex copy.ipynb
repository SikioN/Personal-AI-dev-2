{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TComplex + Finetuned E5 Benchmark\n",
    "\n",
    "This notebook benchmarks the performance of the TComplex integration against a Finetuned E5-only baseline on the CronKGQA test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b5915fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to project root: /Users/nmuravya/Desktop/KG_sber/Personal-AI-dev 2\n",
      "Added /Users/nmuravya/Desktop/KG_sber/Personal-AI-dev 2 to sys.path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nmuravya/.pyenv/versions/3.11.7/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.30.2 at schema.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/nmuravya/.pyenv/versions/3.11.7/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.30.2 at common.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/nmuravya/.pyenv/versions/3.11.7/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.30.2 at milvus.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/nmuravya/.pyenv/versions/3.11.7/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.30.2 at rg.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/nmuravya/.pyenv/versions/3.11.7/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.30.2 at feder.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/nmuravya/.pyenv/versions/3.11.7/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.30.2 at msg.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Используется Apple Silicon GPU (MPS)\n",
      "✓ Используется Apple Silicon GPU (MPS)\n",
      "✓ Используется Apple Silicon GPU (MPS)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Robustly set project root\n",
    "def set_project_root():\n",
    "    current_dir = os.getcwd()\n",
    "    if 'notebooks' in current_dir:\n",
    "        while 'src' not in os.listdir(current_dir):\n",
    "            parent = os.path.dirname(current_dir)\n",
    "            if parent == current_dir:\n",
    "                break\n",
    "            current_dir = parent\n",
    "        os.chdir(current_dir)\n",
    "        print(f\"Changed directory to project root: {current_dir}\")\n",
    "    \n",
    "    if current_dir not in sys.path:\n",
    "        sys.path.append(current_dir)\n",
    "        print(f\"Added {current_dir} to sys.path\")\n",
    "\n",
    "set_project_root()\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from src.kg_model.knowledge_graph_model import KnowledgeGraphModel, KnowledgeGraphModelConfig\n",
    "from src.db_drivers.vector_driver.embedders import EmbedderModelConfig\n",
    "from src.kg_model.embeddings_model import EmbeddingsModelConfig\n",
    "from src.db_drivers.vector_driver import VectorDriverConfig, VectorDBConnectionConfig\n",
    "from src.kg_model.graph_model import GraphModelConfig\n",
    "from src.db_drivers.graph_driver import GraphDriverConfig\n",
    "from src.utils.data_structs import TripletCreator\n",
    "from src.utils.kg_navigator import KGNavigator\n",
    "\n",
    "# Force PyTorch\n",
    "os.environ['USE_TF'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff23efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Standalone QA Engine to avoid Import Hell ---\n",
    "class StandaloneQAEngine:\n",
    "    def __init__(self, kg_model, finetuned_model_path):\n",
    "        self.kg_model = kg_model\n",
    "        \n",
    "        # Init Embedder\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        if os.path.exists(finetuned_model_path):\n",
    "            model_name = finetuned_model_path\n",
    "        else:\n",
    "            model_name = \"intfloat/multilingual-e5-small\"\n",
    "            \n",
    "        print(f\"Loading S-BERT: {model_name}\")\n",
    "        self.encoder = SentenceTransformer(model_name)\n",
    "        \n",
    "        # Load Mapper\n",
    "        from src.utils.wikidata_utils import WikidataMapper\n",
    "        kg_data_path = \"wikidata_big/kg\"\n",
    "        self.mapper = WikidataMapper(kg_data_path)\n",
    "        \n",
    "        # Init Temporal Scorer\n",
    "        self.temporal_scorer = None\n",
    "        try:\n",
    "            from src.kg_model.temporal.temporal_model import TemporalScorer\n",
    "            self.temporal_scorer = TemporalScorer(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not initialize TemporalScorer: {e}\")\n",
    "\n",
    "        # Extractor placeholder\n",
    "        self.extractor_override = None \n",
    "\n",
    "    def get_ranked_results(self, query: str, top_k: int = 5):\n",
    "        # 1. Extract entities (Mocked)\n",
    "        if self.extractor_override:\n",
    "            extraction, _ = self.extractor_override.perform(query)\n",
    "            # Handle list or dict return\n",
    "            if isinstance(extraction, list):\n",
    "                item = extraction[0]\n",
    "            else:\n",
    "                item = extraction\n",
    "            entities = item.get('entities', [])\n",
    "            query_time = item.get('time')\n",
    "        else:\n",
    "            entities = [query]\n",
    "            query_time = None\n",
    "            \n",
    "        # 2. Match nodes via Mapper (Strict ID lookup)\n",
    "        mapped_ids = []\n",
    "        for ent in entities:\n",
    "            wd_id = self.mapper.get_id(ent)\n",
    "            if wd_id:\n",
    "                mapped_ids.append(wd_id)\n",
    "        \n",
    "        all_matched_nodes = []\n",
    "        connector = self.kg_model.graph_struct.db_conn\n",
    "        for mid in mapped_ids:\n",
    "            if hasattr(connector, 'strid_nodes_index'):\n",
    "                internal_ids = connector.strid_nodes_index.get(mid, [])\n",
    "                for iid in internal_ids:\n",
    "                    if iid in connector.nodes:\n",
    "                        all_matched_nodes.append(connector.nodes[iid])\n",
    "\n",
    "        if not all_matched_nodes:\n",
    "            return []\n",
    "\n",
    "        # 3. Retrieve Neighborhood\n",
    "        node_ids = [n.id for n in all_matched_nodes]\n",
    "        nav = KGNavigator(self.kg_model)\n",
    "        candidate_triplets = nav.get_neighborhood(node_ids, depth=1)\n",
    "        \n",
    "        if not candidate_triplets:\n",
    "            return []\n",
    "\n",
    "        # Deduplicate\n",
    "        seen = set()\n",
    "        unique_candidates = []\n",
    "        for t in candidate_triplets:\n",
    "            if t.id not in seen:\n",
    "                unique_candidates.append(t)\n",
    "                seen.add(t.id)\n",
    "\n",
    "        # 4. Rank\n",
    "        query_emb = self.encoder.encode([query])[0]\n",
    "        \n",
    "        triplets_text = []\n",
    "        for t in unique_candidates:\n",
    "             _, text = TripletCreator.stringify(t)\n",
    "             triplets_text.append(text)\n",
    "             \n",
    "        triplet_embs = self.encoder.encode(triplets_text)\n",
    "        \n",
    "        results = []\n",
    "        def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        for t, text, emb in zip(unique_candidates, triplets_text, triplet_embs):\n",
    "            score = np.dot(query_emb, emb) / (np.linalg.norm(query_emb) * np.linalg.norm(emb))\n",
    "            e5_conf = float(max(0, score))\n",
    "            final_conf = e5_conf\n",
    "            \n",
    "            if query_time and self.temporal_scorer:\n",
    "                s_qid = t.start_node.prop.get('wd_id')\n",
    "                r_pid = t.relation.prop.get('wd_id')\n",
    "                o_qid = t.end_node.prop.get('wd_id')\n",
    "                if s_qid and r_pid and o_qid:\n",
    "                    try:\n",
    "                        logit = self.temporal_scorer.score(s_qid, r_pid, o_qid, query_time)\n",
    "                        # Check if logit is valid (not super negative indicating unknown)\n",
    "                        if logit > -10.0:\n",
    "                            # Weighted combination: 70% Semantic, 30% Temporal\n",
    "                            final_conf = (e5_conf * 0.7) + (sigmoid(logit) * 0.3)\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "            \n",
    "            results.append({'triplet': t, 'confidence': final_conf})\n",
    "            \n",
    "        results.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        return results[:top_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18134a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing QA Engine...\n",
      "✓ Используется Apple Silicon GPU (MPS)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f3127c596a441c9d4faa77a872973b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: intfloat/multilingual-e5-small\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hydrating graph from wikidata_big/kg/full.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing triplets: 100%|██████████| 328635/328635 [00:05<00:00, 62965.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hydration complete. Nodes: 122569, Triplets: 328635\n",
      "Loading S-BERT: intfloat/multilingual-e5-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6a5f0360cf463985ddc68a629c432d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: intfloat/multilingual-e5-small\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TemporalScorer resources from wikidata_big/kg/tkbc_processed_data/wikidata_big/...\n",
      "Loaded mappings: 125726 entities, 203 relations, 9621 timestamps\n",
      "Loading weights from models/cronkgqa/tcomplex.ckpt...\n",
      "TemporalScorer initialized successfully.\n",
      "Engine Ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing QA Engine...\")\n",
    "\n",
    "# 1. Initialize QA Engine with headless config\n",
    "g_driver_conf = GraphDriverConfig(db_vendor='inmemory_graph')\n",
    "g_model_conf = GraphModelConfig(driver_config=g_driver_conf)\n",
    "\n",
    "model_path = \"models/finetuned_e5\"\n",
    "if not os.path.exists(model_path):\n",
    "    model_path = \"intfloat/multilingual-e5-small\"\n",
    "    \n",
    "emb_conf = EmbedderModelConfig(model_name_or_path=model_path)\n",
    "\n",
    "# Correct paths for vector DBs\n",
    "nodes_path = \"data/graph_structures/vectorized_nodes/wikidata_test\"\n",
    "triplets_path = \"data/graph_structures/vectorized_triplets/wikidata_test\"\n",
    "\n",
    "nodes_cfg = VectorDriverConfig(\n",
    "    db_vendor='chroma', db_config=VectorDBConnectionConfig(\n",
    "        conn={'path': nodes_path},\n",
    "        db_info={'db': 'default_db', 'table': \"personalaitable\"}))\n",
    "        \n",
    "triplets_cfg = VectorDriverConfig(\n",
    "    db_vendor='chroma', db_config=VectorDBConnectionConfig(\n",
    "        conn={'path': triplets_path},\n",
    "        db_info={'db': 'default_db', 'table': \"personalaitable\"}))\n",
    "\n",
    "embs_conf = EmbeddingsModelConfig(\n",
    "    nodesdb_driver_config=nodes_cfg,\n",
    "    tripletsdb_driver_config=triplets_cfg,\n",
    "    embedder_config=emb_conf\n",
    ")\n",
    "\n",
    "kg_conf = KnowledgeGraphModelConfig(graph_config=g_model_conf, embeddings_config=embs_conf)\n",
    "kg_model = KnowledgeGraphModel(config=kg_conf)\n",
    "\n",
    "# Hydrate Graph (Crucial for ID mapping)\n",
    "from src.utils.wikidata_utils import WikidataMapper\n",
    "from src.utils.graph_loader import hydrate_in_memory_graph\n",
    "kg_data_path = \"wikidata_big/kg\"\n",
    "mapper = WikidataMapper(kg_data_path)\n",
    "hydrate_in_memory_graph(kg_model, mapper, kg_data_path)\n",
    "\n",
    "# Init Engine using Standalone class\n",
    "engine = StandaloneQAEngine(kg_model, model_path)\n",
    "print(\"Engine Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be2c3996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test Data\n",
    "test_path = 'wikidata_big/questions/test.pickle'\n",
    "with open(test_path, 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "# Helper classes\n",
    "class MockExtractor:\n",
    "    def __init__(self, entities, time=None):\n",
    "        self.entities = list(entities)\n",
    "        self.time = time\n",
    "    def perform(self, query):\n",
    "        return [{'entities': self.entities, 'time': self.time}], None\n",
    "\n",
    "def evaluate_sample(sample_data, use_temporal=True):\n",
    "    results = []\n",
    "    # Toggle scorer\n",
    "    original_scorer = engine.temporal_scorer\n",
    "    if not use_temporal:\n",
    "        engine.temporal_scorer = None\n",
    "        \n",
    "    for item in tqdm(sample_data):\n",
    "        q = item['question']\n",
    "        gt_ids = item['entities']\n",
    "        answers = item['answers']\n",
    "        \n",
    "        # Map IDs to Names for Search\n",
    "        names = [mapper.get_label(qid) for qid in gt_ids]\n",
    "        \n",
    "        # IMPROVED: Extract time from dataset 'times' field if available\n",
    "        # Fallback to regex if 'times' is empty\n",
    "        t_set = item.get('times', set())\n",
    "        if t_set and len(t_set) > 0:\n",
    "            # Take the first year found\n",
    "            t = list(t_set)[0]\n",
    "        else:\n",
    "            matches = re.findall(r'\\b(1\\d{3}|20\\d{2})\\b', q)\n",
    "            t = int(matches[0]) if matches else None\n",
    "        \n",
    "        engine.extractor_override = MockExtractor(names, t)\n",
    "        \n",
    "        try:\n",
    "            ranked = engine.get_ranked_results(q, top_k=10)\n",
    "        except Exception as e:\n",
    "            ranked = []\n",
    "            \n",
    "        rank = 1000\n",
    "        \n",
    "        # Special logic for simple_time (Answer is a Year, not Entity ID)\n",
    "        if item['type'] == 'simple_time':\n",
    "            for i, res in enumerate(ranked):\n",
    "                t_obj = res['triplet']\n",
    "                extracted_year = None\n",
    "                \n",
    "                # Try to find time in triplet properties\n",
    "                # 1. Triplet.time node\n",
    "                if t_obj.time and t_obj.time.name:\n",
    "                    extracted_year = t_obj.time.name\n",
    "                # 2. Relation property\n",
    "                elif 'time' in t_obj.relation.prop:\n",
    "                    extracted_year = t_obj.relation.prop['time']\n",
    "                # 3. End node property (common for episodic)\n",
    "                elif 'time' in t_obj.end_node.prop:\n",
    "                    extracted_year = t_obj.end_node.prop['time']\n",
    "                \n",
    "                # Check if extracted year matches any answer\n",
    "                if extracted_year:\n",
    "                    try:\n",
    "                        # Handle date strings like \"2008-01-01\" or \"2008\"\n",
    "                        y_str = str(extracted_year).split('-')[0]\n",
    "                        if y_str.isdigit():\n",
    "                             y_int = int(y_str)\n",
    "                             # Answers are a set of ints or strings.\n",
    "                             if y_int in answers or str(y_int) in answers:\n",
    "                                 rank = i + 1\n",
    "                                 break\n",
    "                    except:\n",
    "                        pass\n",
    "        else:\n",
    "            # Standard Entity Logic\n",
    "            for i, res in enumerate(ranked):\n",
    "                t = res['triplet']\n",
    "                s = t.start_node.prop.get('wd_id')\n",
    "                o = t.end_node.prop.get('wd_id')\n",
    "                if s in answers or o in answers:\n",
    "                    rank = i + 1\n",
    "                    break\n",
    "        \n",
    "        results.append({\n",
    "            'question_type': item['type'],\n",
    "            'rank': rank,\n",
    "            'hit_1': 1 if rank == 1 else 0,\n",
    "            'hit_5': 1 if rank <= 5 else 0,\n",
    "            'mrr': 1.0/rank if rank <= 10 else 0.0\n",
    "        })\n",
    "        \n",
    "    engine.temporal_scorer = original_scorer\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edeb35bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd252e5c8534ed8bc3fc1c49774ead4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Proposed...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1117cb16f6742b189ba99e47c8b8c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Run Benchmark\n",
    "SAMPLE_SIZE = 500 # Adjust as needed\n",
    "subset = test_data[:SAMPLE_SIZE]\n",
    "\n",
    "print(\"Running Baseline...\")\n",
    "df_base = evaluate_sample(subset, use_temporal=False)\n",
    "\n",
    "print(\"Running Proposed...\")\n",
    "df_prop = evaluate_sample(subset, use_temporal=True)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd52f9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Config           Type       MRR    Hits@1    Hits@5\n",
      "0   Baseline        Overall  0.514787  0.440000  0.620000\n",
      "1   Proposed        Overall  0.517887  0.444000  0.620000\n",
      "6   Baseline   before_after  0.231810  0.161290  0.322581\n",
      "7   Proposed   before_after  0.231810  0.161290  0.322581\n",
      "4   Baseline     first_last  0.373344  0.309524  0.446429\n",
      "5   Proposed     first_last  0.373344  0.309524  0.446429\n",
      "10  Baseline  simple_entity  0.892109  0.843972  0.957447\n",
      "11  Proposed  simple_entity  0.903101  0.858156  0.957447\n",
      "8   Baseline    simple_time  0.425335  0.330097  0.572816\n",
      "9   Proposed    simple_time  0.425335  0.330097  0.572816\n",
      "2   Baseline      time_join  0.313840  0.175439  0.543860\n",
      "3   Proposed      time_join  0.313840  0.175439  0.543860\n"
     ]
    }
   ],
   "source": [
    "# Analysis\n",
    "def compare_metrics(df_base, df_prop):\n",
    "    metrics = []\n",
    "    # Overall\n",
    "    for name, df in [('Baseline', df_base), ('Proposed', df_prop)]:\n",
    "        metrics.append({\n",
    "            'Config': name,\n",
    "            'Type': 'Overall',\n",
    "            'MRR': df['mrr'].mean(),\n",
    "            'Hits@1': df['hit_1'].mean(),\n",
    "            'Hits@5': df['hit_5'].mean()\n",
    "        })\n",
    "    # Per Type\n",
    "    types = df_base['question_type'].unique()\n",
    "    for t in types:\n",
    "        for name, df in [('Baseline', df_base), ('Proposed', df_prop)]:\n",
    "            sub = df[df['question_type'] == t]\n",
    "            metrics.append({\n",
    "                'Config': name,\n",
    "                'Type': t,\n",
    "                'MRR': sub['mrr'].mean(),\n",
    "                'Hits@1': sub['hit_1'].mean(),\n",
    "                'Hits@5': sub['hit_5'].mean()\n",
    "            })\n",
    "    return pd.DataFrame(metrics).sort_values(['Type', 'Config'])\n",
    "\n",
    "final = compare_metrics(df_base, df_prop)\n",
    "print(final)\n",
    "final.to_csv(\"benchmark_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d52a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6474c521",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
