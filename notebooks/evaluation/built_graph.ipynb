{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "\n",
    "# TO CHANGE\n",
    "BASEDIR = \"../../\"\n",
    "sys.path.insert(0, BASEDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzigen/Desktop/PersonalAI/pai_venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "TRIALS = 2\n",
    "FIX_FILE_PATH = \"./import_fix.py\"\n",
    "for _ in range(TRIALS):\n",
    "    try:\n",
    "      from src import PersonalAI, PersonalAIConfig, QAPipelineConfig, MemPipelineConfig, \\\n",
    "            GraphModelConfig, EmbeddingsModelConfig, EmbedderModelConfig\n",
    "\n",
    "      from src.db_drivers import KeyValueDriverConfig, GraphDriverConfig, VectorDriverConfig\n",
    "      from src.db_drivers.kv_driver import DEFAULT_INMEMORYKV_CONFIG\n",
    "      from src.db_drivers.graph_driver import DEFAULT_INMEMORYGRAPH_CONFIG\n",
    "      from src.db_drivers.vector_driver import VectorDBConnectionConfig\n",
    "\n",
    "      from src.pipelines.qa.knowledge_retriever import AStarGraphSearchConfig, AStarMetricsConfig, BFSSearchConfig, MixturedGraphSearchConfig\n",
    "      from src.pipelines.qa import QueryLLMParserConfig, KnowledgeComparatorConfig, KnowledgeRetrieverConfig, QALLMGeneratorConfig\n",
    "\n",
    "      from src.pipelines.memorize import LLMExtractorConfig, LLMUpdatorConfig\n",
    "\n",
    "      from src.utils import NodeType, Logger\n",
    "    except RuntimeError as e:\n",
    "        from pathlib import Path\n",
    "        fix_path = Path(FIX_FILE_PATH)\n",
    "        if fix_path.is_file():\n",
    "            %run {fix_path} --base_dir BASEDIR\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Загружем датасет с триплетами, на основе которого будет построен граф знаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283268\n"
     ]
    }
   ],
   "source": [
    "#PKL_GRAPH_PATH = 'C:/Users/nikit/temp_files/pickled_graphs/DiaasqGigachat.pickle'\n",
    "PKL_GRAPH_PATH = '../../data/pickled_graphs/DiaasqGPT4omini.pickle'\n",
    "#PKL_GRAPH_PATH = '../../data/pickled_graphs/DiaasqGigachat.pickle'\n",
    "\n",
    "with open(PKL_GRAPH_PATH, 'rb') as f:\n",
    "    formated_triplets = pickle.load(f)\n",
    "print(len(formated_triplets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Задаём конфигурацию графа знаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph model configuration\n",
    "GRAPH_STORAGE_CONFIG = GraphDriverConfig(db_vendor='inmemory_graph', db_config=DEFAULT_INMEMORYGRAPH_CONFIG)\n",
    "GRAPH_MODEL_CONFIG = GraphModelConfig(driver_config=GRAPH_STORAGE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector model configuration\n",
    "NODES_DB_PATH = '../../data/graph_structures/vectorized_nodes/testing' # TO CHANGE\n",
    "TRIPLETS_DB_PATH = '../../data/graph_structures/vectorized_triplets/testing' # TO CHANGE\n",
    "NEED_TO_CLEAR = True\n",
    "\n",
    "VECTOR_NODES_STORAGE_CONFIG = VectorDriverConfig(db_config=VectorDBConnectionConfig(path=NODES_DB_PATH, need_to_clear=NEED_TO_CLEAR))\n",
    "VECTOR_TRIPLETS_STIRAGE_CONFIG = VectorDriverConfig(db_config=VectorDBConnectionConfig(path=TRIPLETS_DB_PATH, need_to_clear=NEED_TO_CLEAR))\n",
    "\n",
    "DEVICE = 'cuda' # TO CHANGE\n",
    "EMBEDDER_MODEL_PATH = '../../models/intfloat/multilingual-e5-small' # TO CHANGE\n",
    "EMBEDDER_MODEL_CONFIG = EmbedderModelConfig(model_name_or_path=EMBEDDER_MODEL_PATH, device=DEVICE)\n",
    "\n",
    "VECTOR_MODEL_CONFIG = EmbeddingsModelConfig(\n",
    "    nodesdb_driver_config=VECTOR_NODES_STORAGE_CONFIG,\n",
    "    tripletsdb_driver_config=VECTOR_TRIPLETS_STIRAGE_CONFIG,\n",
    "    embedder_config=EMBEDDER_MODEL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA-pipeline retrieve stage configuration (configuring mixture graph search/retriever)\n",
    "KV_STORAGE_CONFIG = KeyValueDriverConfig(db_vendor='inmemory_kv', db_config=DEFAULT_INMEMORYKV_CONFIG)\n",
    "ASTAR_RETRIEVER_CONFIG = AStarGraphSearchConfig(\n",
    "    metrics_config=AStarMetricsConfig(\n",
    "        h_metric_name='ip', # TO CHANGE \n",
    "        kvdriver_config=KV_STORAGE_CONFIG),\n",
    "    max_depth=20, max_passed_nodes=1000, # TO CHANGE\n",
    "    accepted_node_types=[NodeType.object , NodeType.hyper, NodeType.episodic]) # TO CHANGE\n",
    "\n",
    "BFS_RETRIEVER_CONFIG = BFSSearchConfig(\n",
    "    strict_filter = True, hyper_episodic_num = 15, # TO CHANGE\n",
    "    chain_triplets_num = 25, other_triplets_num = 6) # TO CHANGE\n",
    "\n",
    "RETRIEVER_NAME = 'mixture'\n",
    "RETRIEVER_CONFIG = MixturedGraphSearchConfig(\n",
    "    astar_config=ASTAR_RETRIEVER_CONFIG,\n",
    "    bfs_config=BFS_RETRIEVER_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = 'en' # TO CHANGE ('ru' | 'en' | 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA-pipeline configuration\n",
    "QA_PIPELINE_CONFIG = QAPipelineConfig(\n",
    "    query_parser_config=QueryLLMParserConfig(lang=LANGUAGE),\n",
    "    knowledge_comparator_config=KnowledgeComparatorConfig(),\n",
    "    knowledge_retriever_config=KnowledgeRetrieverConfig(\n",
    "        retriever_method=RETRIEVER_NAME,retriever_config=RETRIEVER_CONFIG),\n",
    "    answer_generator_config=QALLMGeneratorConfig(lang=LANGUAGE))\n",
    "\n",
    "# Memorize-pipeline configuration\n",
    "MEM_PIPELINE_CONFIG = MemPipelineConfig(\n",
    "    extractor_config=LLMExtractorConfig(lang=LANGUAGE),\n",
    "    updator_config=LLMUpdatorConfig(lang=LANGUAGE))\n",
    "\n",
    "PERSONALAI_CONFIG = PersonalAIConfig(\n",
    "    graph_struct_config=GRAPH_MODEL_CONFIG,\n",
    "    embedds_struct_config=VECTOR_MODEL_CONFIG,\n",
    "    qa_pipeline_config=QA_PIPELINE_CONFIG,\n",
    "    mem_pipeline_config=MEM_PIPELINE_CONFIG,\n",
    "    log=Logger('log/main'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Инициализируем граф знаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name ../../models/intfloat/multilingual-e5-small. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "personalai = PersonalAI(config=PERSONALAI_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Добавляем в граф загруженные триплеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"uploading data to graph-storage\")\n",
    "graph_info = personalai.kg_model.graph_struct.create_triplets(formated_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"uploading data to vector-storage\")\n",
    "vector_info = personalai.kg_model.embeddings_struct.create_triplets(formated_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1000\n",
    "# QUESTION_NUM = 20\n",
    "# episodic_text = []\n",
    "# for i in range(N):\n",
    "#     if formated_triplets[i].end_node.type.value == 'episodic':\n",
    "#         episodic_text.append(formated_triplets[i].end_node.name)\n",
    "# unique_episodic_texts = list(set(episodic_text))\n",
    "# print(len(episodic_text), len(unique_episodic_texts))\n",
    "\n",
    "# llm_agent = GigaChatAgent()\n",
    "\n",
    "# QUESTION_GEN_PROMPT = \"Generate one question based on given dialogue below. Generate question in English.\\n\\nDialogue:\\n{d}\\n\\nQuestion:\\n\"\n",
    "# ANSWER_GEN_PROMPT = \"Generate answer for the question based on given dialogue below. Generate answer in English. Answer needs to be generated in a short format: in several phrases; dont generate full sentence as an answer.\\n\\nDialogue:\\n{d}\\n\\nQuestion:{q}\\n\\nAnswer:\\n\"\n",
    "\n",
    "# qa_examples = []\n",
    "# for text in tqdm(unique_episodic_texts[:QUESTION_NUM]):\n",
    "#     question = llm_agent.generate(user_prompt=QUESTION_GEN_PROMPT.format(d=text)).strip()\n",
    "#     answer = llm_agent.generate(user_prompt=ANSWER_GEN_PROMPT.format(d=text, q=question)).strip()\n",
    "#     print(\"Q: \", question)\n",
    "#     print(\"A: \", answer)\n",
    "#     qa_examples.append((question, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_examples = [\n",
    "  (\"What is Lauren's opinion about the 13promax battery compared to other batteries in terms of battery life?\",\n",
    "  'Lauren thinks the 13promax battery has better battery life than other batteries in mobile phones.'),\n",
    "  (\"What does Emily think about the performance of her brother's GT2PRO and IQOO7 smartphones during voice calls.\",\n",
    "  'Emily thinks GT2PRO is not as hot during voice calls compared to IQOO7.'),\n",
    "  (\"What is the difference between the heat dissipation performance of the IQOO9 and Xiaomi Mi 12Pro smartphones according to Laura's experience?\",\n",
    "  'Laura finds the heat dissipation performance of the IQOO9 superior to the Xiaomi Mi 12Pro, resulting in less heating while using it for long periods.'),\n",
    "  (\"What are the reasons behind Rodrigo's dislike for Xiaomi's MIUI software, specifically mentioning the frequent bugs he has experienced over the past two years?\",\n",
    "  \"Rodrigo dislikes Xiaomi's MIUI software due to frequent bugs he has experienced over the past two years, including small bugs that affect usage, such as force restarts.\"),\n",
    "  (\"What is Margaret's main concern regarding her MIX4 smartphone?\",\n",
    "  \"problem with the photography camera module and its poor performance.\"),\n",
    "  ('What are the advantages of the Xiaomi Mi 10pro mentioned by Horace and Jesse, especially in comparison to other devices?',\n",
    "  'Advantages of Xiaomi Mi 10pro: splitscreen capability, fast charging, screen durability, waterproofing, good signal strength, fast gaming performance. Comparatively better than other devices (especially Apple) in terms of battery life and signal strength.'),\n",
    "  ('What issues have James and Hailey experienced with their MIX4 devices, especially regarding the photography camera module?',\n",
    "  \"James experienced multiple crashes in a short period, while Hailey mentioned her device being used many times.\"),\n",
    "  (\"What was Kevin's experience with his brother's GT2PRO and Xiaomi 10Pro?\",\n",
    "  \"Kevin found his brother's GT2PRO less hot than expected during voice calls, while Xiaomi 10Pro didn't heat up when recording videos.\"),\n",
    "  (\"What mobile phone does Kayla's brother have that doesn't get hot during voice calls, according to her?\",\n",
    "  \"IQOO7\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Kevin's experiences with his brother's GT2PRO and Xiaomi 10Pro included observations about the devices' relative performance compared to Apple products, particularly regarding signal strength and battery life. He expressed concern about signal issues with Xiaomi and hesitation in switching to Apple due to signal and electrical issues.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer, info = personalai.answer_question(qa_examples[-2][0])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
