{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "\n",
    "# TO CHANGE\n",
    "BASEDIR = \"../../\"\n",
    "sys.path.insert(0, BASEDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzigen/Desktop/PersonalAI/pai_venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "TRIALS = 2\n",
    "FIX_FILE_PATH = \"./import_fix.py\"\n",
    "for _ in range(TRIALS):\n",
    "    try:\n",
    "      from src import PersonalAI, PersonalAIConfig, QAPipelineConfig, MemPipelineConfig, \\\n",
    "            GraphModelConfig, EmbeddingsModelConfig, EmbedderModelConfig\n",
    "\n",
    "      from src.db_drivers import KeyValueDriverConfig, GraphDriverConfig, VectorDriverConfig\n",
    "      from src.db_drivers.kv_driver import DEFAULT_INMEMORYKV_CONFIG\n",
    "      from src.db_drivers.graph_driver import DEFAULT_INMEMORYGRAPH_CONFIG\n",
    "      from src.db_drivers.vector_driver import VectorDBConnectionConfig\n",
    "\n",
    "      from src.pipelines.qa.knowledge_retriever import AStarGraphSearchConfig, AStarMetricsConfig, BFSSearchConfig, MixturedGraphSearchConfig\n",
    "      from src.pipelines.qa import QueryLLMParserConfig, KnowledgeComparatorConfig, KnowledgeRetrieverConfig, QALLMGeneratorConfig\n",
    "\n",
    "      from src.pipelines.memorize import LLMExtractorConfig, LLMUpdatorConfig\n",
    "\n",
    "      from src.utils import NodeType, Logger\n",
    "    except RuntimeError as e:\n",
    "        from pathlib import Path\n",
    "        fix_path = Path(FIX_FILE_PATH)\n",
    "        if fix_path.is_file():\n",
    "            %run {fix_path} --base_dir BASEDIR\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Загружем датасет с триплетами, на основе которого будет построен граф знаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PKL_GRAPH_PATH = '../../data/pickled_graphs/testdb.pickle'\n",
    "\n",
    "with open(PKL_GRAPH_PATH, 'rb') as f:\n",
    "    formated_triplets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10355\n",
      "10355\n"
     ]
    }
   ],
   "source": [
    "length = 10355\n",
    "\n",
    "print(len(formated_triplets))\n",
    "formated_triplets = formated_triplets[:length]\n",
    "print(len(formated_triplets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Задаём конфигурацию графа знаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph model configuration\n",
    "GRAPH_STORAGE_CONFIG = GraphDriverConfig(db_vendor='inmemory_graph', db_config=DEFAULT_INMEMORYGRAPH_CONFIG)\n",
    "GRAPH_MODEL_CONFIG = GraphModelConfig(driver_config=GRAPH_STORAGE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector model configuration\n",
    "NODES_DB_PATH = '../../data/graph_structures/vectorized_nodes/testing' # TO CHANGE\n",
    "TRIPLETS_DB_PATH = '../../data/graph_structures/vectorized_triplets/testing' # TO CHANGE\n",
    "NEED_TO_CLEAR = True\n",
    "\n",
    "VECTOR_NODES_STORAGE_CONFIG = VectorDriverConfig(db_config=VectorDBConnectionConfig(path=NODES_DB_PATH, need_to_clear=NEED_TO_CLEAR))\n",
    "VECTOR_TRIPLETS_STIRAGE_CONFIG = VectorDriverConfig(db_config=VectorDBConnectionConfig(path=TRIPLETS_DB_PATH, need_to_clear=NEED_TO_CLEAR))\n",
    "\n",
    "DEVICE = 'cuda' # TO CHANGE\n",
    "EMBEDDER_MODEL_PATH = '../../models/intfloat/multilingual-e5-small' # TO CHANGE\n",
    "EMBEDDER_MODEL_CONFIG = EmbedderModelConfig(model_name_or_path=EMBEDDER_MODEL_PATH, device=DEVICE)\n",
    "\n",
    "VECTOR_MODEL_CONFIG = EmbeddingsModelConfig(\n",
    "    nodesdb_driver_config=VECTOR_NODES_STORAGE_CONFIG,\n",
    "    tripletsdb_driver_config=VECTOR_TRIPLETS_STIRAGE_CONFIG,\n",
    "    embedder_config=EMBEDDER_MODEL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA-pipeline retrieve stage configuration (configuring mixture graph search/retriever)\n",
    "KV_STORAGE_CONFIG = KeyValueDriverConfig(db_vendor='inmemory_kv', db_config=DEFAULT_INMEMORYKV_CONFIG)\n",
    "ASTAR_RETRIEVER_CONFIG = AStarGraphSearchConfig(\n",
    "    metrics_config=AStarMetricsConfig(\n",
    "        h_metric_name='ip', # TO CHANGE \n",
    "        kvdriver_config=KV_STORAGE_CONFIG),\n",
    "    max_depth=20, max_passed_nodes=1000, # TO CHANGE\n",
    "    accepted_node_types=[NodeType.object , NodeType.hyper, NodeType.episodic]) # TO CHANGE\n",
    "\n",
    "BFS_RETRIEVER_CONFIG = BFSSearchConfig(\n",
    "    strict_filter = True, hyper_episodic_num = 15, # TO CHANGE\n",
    "    chain_triplets_num = 25, other_triplets_num = 6) # TO CHANGE\n",
    "\n",
    "RETRIEVER_NAME = 'mixture'\n",
    "RETRIEVER_CONFIG = MixturedGraphSearchConfig(\n",
    "    astar_config=ASTAR_RETRIEVER_CONFIG,\n",
    "    bfs_config=BFS_RETRIEVER_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = 'en' # TO CHANGE ('ru' | 'en' | 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA-pipeline configuration\n",
    "QA_PIPELINE_CONFIG = QAPipelineConfig(\n",
    "    query_parser_config=QueryLLMParserConfig(lang=LANGUAGE),\n",
    "    knowledge_comparator_config=KnowledgeComparatorConfig(),\n",
    "    knowledge_retriever_config=KnowledgeRetrieverConfig(\n",
    "        retriever_method=RETRIEVER_NAME,retriever_config=RETRIEVER_CONFIG),\n",
    "    answer_generator_config=QALLMGeneratorConfig(lang=LANGUAGE))\n",
    "\n",
    "# Memorize-pipeline configuration\n",
    "MEM_PIPELINE_CONFIG = MemPipelineConfig(\n",
    "    extractor_config=LLMExtractorConfig(lang=LANGUAGE),\n",
    "    updator_config=LLMUpdatorConfig(lang=LANGUAGE))\n",
    "\n",
    "PERSONALAI_CONFIG = PersonalAIConfig(\n",
    "    graph_struct_config=GRAPH_MODEL_CONFIG,\n",
    "    embedds_struct_config=VECTOR_MODEL_CONFIG,\n",
    "    qa_pipeline_config=QA_PIPELINE_CONFIG,\n",
    "    mem_pipeline_config=MEM_PIPELINE_CONFIG,\n",
    "    log=Logger('log/main'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Инициализируем граф знаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name ../../models/intfloat/multilingual-e5-small. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "personalai = PersonalAI(config=PERSONALAI_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Добавляем в граф загруженные триплеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10355/10355 [00:00<00:00, 173751.01it/s]\n",
      "100%|██████████| 81/81 [01:19<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"uploading data to graph-storage\")\n",
    "graph_info = personalai.kg_model.graph_struct.create_triplets(formated_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"uploading data to vector-storage\")\n",
    "vector_info = personalai.kg_model.embeddings_struct.create_triplets(formated_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_examples = [\n",
    "  (\"Which device is better in battery life: iPhone11 Pro Max or Xiaomi 11?\",\n",
    "  \"Xiaomi 11\"),\n",
    "  (\"Kayla has positive, negative or neutral opinion about video of 10PRO on 25.11.2020?\",\n",
    "  \"Negative\"),\n",
    "  (\"Do Jane and Jonathan have any common devices (which Jane and Jonathan both use)? If so, list common devices. Otherwise, answer 'No'.\",\n",
    "  \"Xiaomi\"),\n",
    "  (\"Whose opinions from Freda and Bruce about devices are most similar to Kayla's?\",\n",
    "  \"Freda\"),\n",
    "  (\"Which people have negative opinion about video of 10PRO on 25.11.2020?\",\n",
    "  \"Kayla\"),\n",
    "  (\"Which people have positive opinion about signal of Mi 10pro on 22.12.2018?\",\n",
    "  \"Matthew\"),\n",
    "  (\"Jessica has positive, negative or neutral opinion about signal of Apple on 22.12.2018?\",\n",
    "  \"Negative\")\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:  ReturnInfo(occurred_warning=[], status=<ReturnStatus.success: 0>, message='')\n",
      "MODEL ANSWER:  It is unclear which device, iPhone 11 Pro Max or Xiaomi 11, is better in battery life since opinions vary widely.\n",
      "TRUE ANSWER:  Xiaomi 11\n",
      "===================================\n",
      "INFO:  ReturnInfo(occurred_warning=[], status=<ReturnStatus.success: 0>, message='')\n",
      "MODEL ANSWER:  Negative\n",
      "TRUE ANSWER:  Negative\n",
      "===================================\n",
      "INFO:  ReturnInfo(occurred_warning=[], status=<ReturnStatus.success: 0>, message='')\n",
      "MODEL ANSWER:  Yes, Xiaomi\n",
      "TRUE ANSWER:  Xiaomi\n",
      "===================================\n",
      "INFO:  ReturnInfo(occurred_warning=[], status=<ReturnStatus.success: 0>, message='')\n",
      "MODEL ANSWER:  There is no direct comparison that aligns with Kayla's opinions.\n",
      "TRUE ANSWER:  Freda\n",
      "===================================\n",
      "INFO:  ReturnInfo(occurred_warning=[], status=<ReturnStatus.success: 0>, message='')\n",
      "MODEL ANSWER:  Final answer 3:\n",
      "TRUE ANSWER:  Kayla\n",
      "===================================\n",
      "INFO:  ReturnInfo(occurred_warning=[], status=<ReturnStatus.success: 0>, message='')\n",
      "MODEL ANSWER:  No records found.\n",
      "TRUE ANSWER:  Matthew\n",
      "===================================\n",
      "INFO:  ReturnInfo(occurred_warning=[], status=<ReturnStatus.success: 0>, message='')\n",
      "MODEL ANSWER:  Cannot be determined\n",
      "TRUE ANSWER:  Negative\n",
      "===================================\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for question in qa_examples:\n",
    "    answer, info = personalai.answer_question(question[0])\n",
    "    print(\"INFO: \", info)\n",
    "    print(\"MODEL ANSWER: \", answer)\n",
    "    print(\"TRUE ANSWER: \", question[1])\n",
    "    print(\"=\" * 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
